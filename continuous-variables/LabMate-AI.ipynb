{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please read me first\n",
    "- Make sure 'train_data.csv' and 'all_combos.csv' are in the folder 'LabMate-AI'\n",
    "- This codes take your data and train random forest algorithm. And the ranked and predicted results are given in the \"predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Welcome! Let me work out what is the best experiment for you to run...\n\nStart: 2019/12/09  20:56:54\n\nLoading:  train_data.xlsx\n"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-88df6b404441>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nLoading: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m \u001b[0mfilename1_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[0mall_combos_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilename1_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, parse_cols, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skip_footer, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     return io.parse(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, engine)\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_stringify_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 653\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_data.xlsx'"
     ]
    }
   ],
   "source": [
    "# ALL CODE:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.externals.joblib import dump\n",
    "import seaborn as sns\n",
    "import time\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# def get_colu_num_numerical(filename1_df):#X with no label\n",
    "#     colu = filename1_df.iloc[:,:-1].select_dtypes(exclude=['object']) #extract  columns\n",
    "#     num = len(colu.columns) #get the number of  columns\n",
    "#     return colu, num\n",
    "\n",
    "# def get_colu_num_catagorical(filename1_df):#X with no label\n",
    "#     colu = filename1_df.iloc[:,:-1].select_dtypes(include=['object']) #extract  columns\n",
    "#     num = len(colu.columns) #get the number of  columns\n",
    "#     return colu, num\n",
    "\n",
    "# # find index in all_combos of train_data  \n",
    "# #先在all里面加入索引，然后merge 去交际，留下交际，得到index\n",
    "# def get_train_OHE(filename1_df, all_combos_df):\n",
    "#     All_OHE_df = pd.get_dummies(all_combos_df) # OHE for all data\n",
    "#     copy_df = all_combos_df.copy()\n",
    "#     copy_df['index'] = np.arange(len(all_combos_df.iloc[:,1]))# Creat a new colum for index in all\n",
    "#     X = filename1_df.iloc[:,:-1] #X\n",
    "#     merge_df = pd.merge(copy_df, X, how='inner') #Merge data from unconverted formation\n",
    "#     index_lst = merge_df['index'].tolist()\n",
    "#     X_OHE_df = All_OHE_df.iloc[index_lst,:]\n",
    "#     return X_OHE_df\n",
    "\n",
    "# # Get the index of each catagorical data\n",
    "# def get_OHE_index(filename1_df): #from your X\n",
    "#     #get unique num:\n",
    "#     Numerical_colu, Numerical_num = get_colu_num_numerical(filename1_df)#get the number of numerical columns, one-hot-encoded columns should appear behind them.\n",
    "#     Discrete_colu, Discrete_num = get_colu_num_catagorical(filename1_df)\n",
    "#     unique_num = []\n",
    "#     for i in Discrete_colu.columns:\n",
    "#         unique_num.append(len(Discrete_colu[i].unique()))\n",
    "#     index = [Numerical_num]\n",
    "#     count = Numerical_num\n",
    "#     for i in unique_num[:-1]:\n",
    "#         count = count + int(i)\n",
    "#         index.append(count)\n",
    "# #     print('Index of OHE:',index)\n",
    "#     return index\n",
    "\n",
    "#tree interpreter for feature importance\n",
    "#以下是tree interpreter的集成代码\n",
    "# def plot_tree(model,filename1_df, all_combos_df): #model, filename1_df is dataframe of train data. All is dataframe of allcombos.\n",
    "#     X = filename1_df.iloc[:,:-1]\n",
    "#     unseen = pd.concat([all_combos_df, X]).drop_duplicates(keep=False) # drop when you get index\n",
    "#     prediction, bias, contributions = ti.predict(model, unseen)\n",
    "#     contributions = pd.DataFrame(contributions, columns=all_combos_df.columns) #get all the contributions\n",
    "#     plt.figure(figsize=(12, 20))\n",
    "#     contributions.plot.box()\n",
    "#     plt.title('Feature importance')\n",
    "#     plt.savefig('Feature importance.png')\n",
    "#     plt.show()\n",
    "\n",
    "#load data\n",
    "print('Welcome! Let me work out what is the best experiment for you to run...')\n",
    "#filename1 = input(\"Please type in your train data file name: \")\n",
    "#filename2 = input('Please type in your chemical space file name: ')\n",
    "print('\\nStart:', time.strftime(\"%Y/%m/%d  %H:%M:%S\"))\n",
    "filename1 = 'train_data.xlsx'\n",
    "filename2 = 'all_combos.xlsx'\n",
    "print('\\nLoading: ', filename1)\n",
    "\n",
    "filename1_df = pd.read_excel(filename1)\n",
    "all_combos_df = pd.read_excel(filename2)\n",
    "y = filename1_df.iloc[:,-1]\n",
    "X = filename1_df.iloc[:,:-1]\n",
    "\n",
    "print('\\nAll good till now. I am figuring out the best method to analyze your data. Bear with me...')\n",
    "#General stuff\n",
    "seed = 1234\n",
    "kfold = KFold(n_splits = 2, random_state = seed)#\n",
    "scoring = 'neg_mean_absolute_error'\n",
    "model = RandomForestRegressor(random_state=seed)\n",
    "\n",
    "#Parameters to tune\n",
    "# estimators = np.arange(100, 1050, 50) \n",
    "# estimators_int = np.ndarray.tolist(estimators)\n",
    "estimators_int = [200, 500]\n",
    "param_grid = {'n_estimators':estimators_int, 'max_features':['auto', 'sqrt'],\n",
    "              'max_depth':[None ]}#\n",
    "#search best parameters and train\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold, n_jobs=-1)\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "#print the best data cranked out from the grid search\n",
    "np.savetxt('Model_best_score_MAE.txt', [\"best_score: %s\" % grid.best_score_], fmt ='%s')\n",
    "best_params = pd.DataFrame([grid.best_params_], columns=grid.best_params_.keys())\n",
    "best_params.to_csv('best_parameters.txt', sep= '\\t')\n",
    "\n",
    "print('\\n... done! It is going to be lightspeed from here on out! :)')\n",
    "#predict future data\n",
    "unseen = pd.concat([all_combos_df, X]).drop_duplicates(keep=False) # drop when you get index\n",
    "model2 = grid.best_estimator_\n",
    "# model2 = RandomForestRegressor(n_estimators = grid.best_params_['n_estimators'], max_features = grid.best_params_['max_features'], max_depth = grid.best_params_['max_depth'], random_state = seed)\n",
    "RF_fit = model2.fit(X, y)\n",
    "predictions = model2.predict(unseen)\n",
    "predictions_df = pd.DataFrame(data=predictions, columns=['Prediction'])\n",
    "\n",
    "# #feature importance\n",
    "# feat_imp = pd.DataFrame(model2.feature_importances_,\n",
    "#                         index=train.iloc[:,1:-1].columns,\n",
    "#                         columns=['Feature_importances'])\n",
    "# feat_imp = feat_imp.sort_values(by=['Feature_importances'], ascending = False)\n",
    "\n",
    "all_predictions = []\n",
    "for e in model2.estimators_:\n",
    "    all_predictions += [e.predict(unseen)]\n",
    "\n",
    "variance = np.var(all_predictions, axis=0)\n",
    "variance_df = pd.DataFrame(data=variance, columns=['Variance'])\n",
    "\n",
    "assert len(variance) == len(predictions)\n",
    "# unseen_combos_df = pd.concat([all_combos_df, X]).drop_duplicates(keep=False)\n",
    "df = pd.concat([unseen, predictions_df, variance_df], axis=1)\n",
    "\n",
    "prediction, bias, contributions = ti.predict(model2, unseen)\n",
    "contributions = pd.DataFrame(contributions, columns=all_combos_df.columns) #get all the contributions\n",
    "plt.figure(figsize=(12, 20))\n",
    "contributions.plot.box()\n",
    "plt.title('Feature importance')\n",
    "plt.savefig('Feature importance.png')\n",
    "plt.show()\n",
    "\n",
    "print('Analysing feature importance for you...')\n",
    "plot_tree(model2, filename1_df, all_combos_df)\n",
    "#save data\n",
    "df.to_csv('predictions.csv',index=False)\n",
    "print('\\nYou are all set! Have a good one, mate!')#all_comboss.csv\n",
    "print('\\nEnd:', time.strftime(\"%Y/%m/%d  %H:%M:%S\"))#train_data.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}